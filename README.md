ğŸ§  IntelliSearch-AI
Local AI RAG-based File Contextâ€“Aware Search Engine
# ğŸ§  IntelliSearch-AI  
## Local AI RAG-based File Contextâ€“Aware Search Engine

IntelliSearch-AI is a **local, privacy-first AI search system** that indexes files on your PC and lets you **ask natural-language questions** about their contents.

It supports **documents, code files, spreadsheets, PDFs, and images**, using **local embeddings + FAISS + an optional local LLM (Ollama)** to deliver context-aware answers â€” without sending your data to the cloud.

---

## ğŸš€ Key Features

- ğŸ” Semantic (meaning-based) file search  
- ğŸ§  Context-aware RAG (Retrieval Augmented Generation)  
- ğŸ“„ Supports PDF, DOCX, PPTX, TXT, CSV, XLS/XLSX, code files  
- ğŸ–¼ï¸ Image understanding via automatic captioning  
- âš¡ FAISS vector database for fast local search  
- ğŸ”„ Delta indexing (watchdog mode) â€” updates only changed files  
- ğŸ’¬ CLI Chat + ğŸ–¥ï¸ GUI Chat (Tkinter)  
- ğŸ›¡ï¸ Fully local & privacy-first  
- ğŸ§© Clean, modular, production-style project structure

- Ask questions like:
â€œWhich file talks about transformers?â€
â€œOpen the file that contains authentication logicâ€
â€œSummarize the PDF about machine learningâ€
---

## ğŸ§  How It Works

1. **Indexing**
   - Files are parsed and chunked
   - Text is summarized
   - Images are captioned
   - Everything is embedded and stored locally using FAISS

2. **Search**
   - User asks a natural-language query
   - FAISS retrieves relevant chunks
   - Context is dynamically assembled

3. **Answering**
   - If Ollama is available â†’ LLM synthesizes an answer
   - Otherwise â†’ semantic search results are shown

---

## ğŸ› ï¸ Setup

1ï¸âƒ£ Clone the Repository

git clone https://github.com/infinity-guy/IntelliSearch-AI.git
cd IntelliSearch-AI

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.venv\Scripts\activate     # Windows
.venv/bin/activate  # Linux / macOS

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
First run may download models and take a few minutes.

4ï¸âƒ£ Install Ollama for LLM Answers (Recommended)
Download Ollama: https://ollama.com
ollama pull tinyllama:1.1b
(Without Ollama, IntelliSearch-AI still works in search-only mode.)

â–¶ï¸ Running the App
python main.py "C:/" - Provide Storage Drive Paths


## ğŸ’¬ Usage Modes
ğŸ”¹ Index (Must Run First Time to build Index Once)
Builds a fresh vector index for the folder.

ğŸ”¹ Chat (CLI)
ğŸ”¹ Watchdog
Incrementally updates the index by detecting:
Added files
Modified files
Deleted files

ğŸ”¹ Chat (GUI)
Desktop UI
Clickable results (Open / Reveal)

## ğŸ”’ Privacy:
âœ… Fully local execution
âœ… No cloud uploads
âœ… No telemetry
âŒ No external APIs required

## ğŸ§ª Tested Environment:
OS: Windows 11
Python: 3.10
Torch: 2.5.1 + CUDA 12.1
GPU: NVIDIA (optional)
LLM: Ollama (tinyllama:1.1b)

## ğŸ§  Why IntelliSearch-AI?
Most AI search tools:
Require cloud APIs
Expose private data
Are closed-source

IntelliSearch-AI is different:
Fully local
Transparent
Hackable
Built like a real system, not a demo

ğŸ™Œ Acknowledgements:
HuggingFace
LangChain
FAISS
Ollama
PyTorch

IntelliSearch-AI is a local, privacy-first AI search system that indexes files on your PC and lets you ask natural-language questions about their contents.

It supports documents, code files, spreadsheets, PDFs, and images, using local embeddings + FAISS + an optional local LLM (Ollama) to deliver context-aware answers â€” without sending your data to the cloud.
ğŸš€ Key Features

    ğŸ” Semantic (meaning-based) file search

    ğŸ§  Context-aware RAG (Retrieval Augmented Generation)

    ğŸ“„ Supports PDF, DOCX, PPTX, TXT, CSV, XLS/XLSX, code files

    ğŸ–¼ï¸ Image understanding via automatic captioning

    âš¡ FAISS vector database for fast local search

    ğŸ”„ Delta indexing (watchdog mode) â€” updates only changed files

    ğŸ’¬ CLI Chat + ğŸ–¥ï¸ GUI Chat (Tkinter)

    ğŸ›¡ï¸ Fully local & privacy-first

    ğŸ§© Clean, modular, production-style project structure

    Ask questions like: â€œWhich file talks about transformers?â€ â€œOpen the file that contains authentication logicâ€ â€œSummarize the PDF about machine learningâ€

ğŸ§  How It Works

    Indexing
        Files are parsed and chunked
        Text is summarized
        Images are captioned
        Everything is embedded and stored locally using FAISS

    Search
        User asks a natural-language query
        FAISS retrieves relevant chunks
        Context is dynamically assembled

    Answering
        If Ollama is available â†’ LLM synthesizes an answer
        Otherwise â†’ semantic search results are shown

ğŸ› ï¸ Setup

1ï¸âƒ£ Clone the Repository

git clone https://github.com/infinity-guy/IntelliSearch-AI.git cd IntelliSearch-AI

2ï¸âƒ£ Create Virtual Environment python -m venv .venv .venv\Scripts\activate # Windows .venv/bin/activate # Linux / macOS

3ï¸âƒ£ Install Dependencies pip install -r requirements.txt First run may download models and take a few minutes.

4ï¸âƒ£ Install Ollama for LLM Answers (Recommended) Download Ollama: https://ollama.com ollama pull tinyllama:1.1b (Without Ollama, IntelliSearch-AI still works in search-only mode.)

â–¶ï¸ Running the App python main.py "C:/" - Provide Storage Drive Paths
ğŸ’¬ Usage Modes

ğŸ”¹ Index (Must Run First Time to build Index Once) Builds a fresh vector index for the folder.

ğŸ”¹ Chat (CLI) ğŸ”¹ Watchdog Incrementally updates the index by detecting: Added files Modified files Deleted files

ğŸ”¹ Chat (GUI) Desktop UI Clickable results (Open / Reveal)
ğŸ”’ Privacy:

âœ… Fully local execution âœ… No cloud uploads âœ… No telemetry âŒ No external APIs required
ğŸ§ª Tested Environment:

OS: Windows 11 Python: 3.10 Torch: 2.5.1 + CUDA 12.1 GPU: NVIDIA (optional) LLM: Ollama (tinyllama:1.1b)
ğŸ§  Why IntelliSearch-AI?

Most AI search tools: Require cloud APIs Expose private data Are closed-source

IntelliSearch-AI is different: Fully local Transparent Hackable Built like a real system, not a demo

ğŸ™Œ Acknowledgements: HuggingFace LangChain FAISS Ollama PyTorch
